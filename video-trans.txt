URL,Transcription

Video URL: https://www.youtube.com/watch?v=UZb0if-7wGE

Video Transcription: 
"So, the past few weeks, I have completely switched from cursor to cloud code and learned a ton of things that made my cloud code super effective. And today I will take you through how do I use cloud code? How did I bring a hero type of spectrum and spectrum process? As well as tips and practical examples of how I use feature like hooks, custom commands, and little tips that made myself much more effective. So with Alfredo, let's get started. But before we dive into that, I know many of you are just getting started learning programming. And one question I got asked a lot is, what does a girl map look like for learning code effectively? That's why I want to introduce you to this free ebook. Maybe I Google's principal analytics lead and data scientist. Where she wrote down all the secret tips and methodologies that she used to learn coding with claw and chat reading. Especially how she get outputed personalized learning role maps based on her specific situation. It also covers all the apps to the fundamentals and basics of coding. Like how do you choose the right coding language to start with and best practice prompt for different coding scenarios like debugging and optimizing the code as well a detailed roadmap of how to master language like Python in just four months. There's even a custom activity that has been taking all the core knowledge of latest, package and learning resource that you can talk to. Alongside detailed video tutorials showcasing her step-by-step work. So I definitely recommend you go take a look if you're just getting started with your coding journey. So the link in the description below for you to download for free. And thanks, Habsport for sharing this awesome material with us. Now let's get back to how do I use Cloud Code. So first, you want to install this Cloud Code extension and sort of allow it to deeply integrate into your current ID like cursor VS code we serve. So now I can click on this run cloud code button and it will automatically open Cloud Code in my current ID. And on the bottom right you should see that it is detecting the specific file in and if I select some lines it will also automatically detect it. You can still use the terminal here as well and you can just do slash ID to choose the specific ID that you wanted to connect to. Next, the first thing before you do anything is that you should run this init command line. So what this init command line do is that they will get Cloud Star analyzing your code base. To learn about what I already set up and what I kind of depend on these components that you should be using. I will also ask your permission to do something. For those type of commands like CD I just don't care. I will just click on always auto approve and you will see this thing is automatically saved as permissions. I know some of you actually want to get Cloud Code always automatically run tools and this is the way you can run that as well. You can do this dangerous, slow, steep permissions. And this will show you that it is bypassing all the permissions so now I will just ask you for permission. So I wouldn't actually recommend this because from my experience, one key advantage of the Cloud Code UX is that allow you to interact with Cloud much better and I will explain what I mean. So after you scan finish, it will try to create this Cloud.md file. If you are using cursor, let's say your cursor rules. And if we click inside, you can see that it automatically detects what is a kind of text stack, what is a run build command, the architecture, the project structure, all the useful stuff. So this gives Cloud a very good base to continue developing new things on top of this repo. And this Cloud md as I mentioned before is pretty much the cursor rules. The only difference is that in cursor, the rules are injected more programmatically, but it for Cloud is much easier. Basically every single run this text you define here is a pen it on top of system message. And I know there are a lot of people who have different source of cursor rules that are to enhance the workflow. For me, it normally is pretty simple. One problem I do add in is this plan and review mode. This basically tells Cloud code there. Before we start working on the project, always in the plan mode to make a plan first. And for the plan, we want to save to this.cloud slash task name.md so that we can keep track that later. And inside this task, we should break down into different tasks. While Cloud code is doing this job, it should also update the plan as we go and a pen what it does into the dog. And this is really useful because it is almost always better to just allow us to Cloud code exactly what I do you want. And this also similar to Amazon's new Kiro workflow as well, where they call it like spec driven development. And what it does is kind of similar. It will ask you to go through the requirements and also kind of go through the architecture design. It's basically the same thing. And obviously you can go as DPS like Kiro where you will break down this three steps process. But I often find it's a fat heavy enough to just do one kind of PRD. So our save this now we can get Cloud code to start implementing our feature. Normally the first thing I will do is make a plan. So I will give probably our building a beautiful online ID from an and help me break down into key components and put them together in the end. And here I'm going to do shift tap. It will first get into this auto accept at its mode, but you want to shift tap again into the panel. So this panel is a... really really useful feature. When the agent is in plan mode, it has this special system prompt and limit access to tools. So it will focus on doing things like web search to understand the latest like text deck or documentation and also planning the architecture. In the end it will generate final reports. And this planning sometimes will take a while. For any feature that is semi-complicated, I will always do this plan mode first. Back in force a few times to align the plan with Cloud Code and only after our getting it start implementing the feature. So here you will see that it is showing task. When you see task, the basic means Cloud Code is calling a subagent that is specifically doing this planning in research. So at default, Cloud Code has 17 different tools. They can do things like rom-com and line, read and find files, file operations and web search. And this task tool, basically means it will launch a new agent for keywords and file search. When Cloud Code agent is calling this task tool, it basically is creating another agent that has almost all the two accept those planning related tools like task to do. And this agent will receive a well-defined tasks from the parent agent to be a list of things that in the end say here are the findings. Only the last part which is summary of the findings will be sent back to the parent Cloud Code agent. And this is one method that they have to really save the token consumption for the parent agent. Because otherwise, the main agent might be flooded with all sorts of contexts. And knowing this, you can actually utilize this task to a lot better. But then what you can't do is promo Cloud Code to use task to set up multiple parallel agent to do different task as same time. But also, if there's a task that you know already, it's going to read some very large files. Try to promo Cloud Code to just use task to do this. Because there will help you save the token a lot on the main agent. So now I finished the planning and the combat with the plan about what does the layout system should look like, file explorer which makes sense. The code editor component is decided to use existing library and then it will break down into different faces. The face one is just install everything and the face two is in Premiere file explorer, code editor, terminal integration, and the sound advanced feature as well as the project directory plan. So this is a pretty good plan and obviously I can keep planning. But here I can also ask it to start do this plan. And next is that it will create this detailed implementation plan in the cloud slash tasks in our click yes. So it will create this task folder and create this online ID from in with the detailed plan and tasks. So now I can ask it to let's do face one and it will create it to do based on the face one requirements. So while it is running, I'm just going to quickly talk about this to do. So I was quite curious how did Cloud Code actually handle this to do? Do they handle it into a different planner agent to just specifically come up with plan and program math play get agent to do one task of another. So I did something investigation. What I found is the entropy team actually took is the the same code is set up possible but it's really effective. It has this tool called to do right. Now you will see the description is basically uses to create a manager structure task list. They have a very specific prompt how about like when to use this tool, when to not use this tool, some example as well. So every time when agent runs this tool, it will try to come up list to do. Each to do will have the content, ID, proud, the end status. It is the same point as this. So now if we come back here, it finished all the to do. It will also going back to our doc and adding details about what it actually did. So in markets that's completed and also document all the things that it does. Cool. So it has this component implemented that it has this file explorer, resize bowl, it has terminal. I can add more of a different terminal as well. Nice. Obviously you can see I can continue going because it already has a trace of the overall plan. So every time it just needs to focus on one specific piece of work. And if there any time when the plan change, we can just prompt it to update the stock. So this kind of my like doc or spec focused workflow with cloud code. But what's really cool about cloud code is that you can customize cloud coding very demand. So once we're interesting feature, there's hooks. So hook is a feature that allows you to define things to happen programmatically when cloud code takes certain actions. One of the most basic and common hook that I use is this stop hook. So I can define a rule here. When cloud code stop, which means it finished the task, it's trying to run this comment, which will basically play the system sound to notify me that the task has been completed. So with this one, if I just send a message to cloud, it will play this notification sound after the task is finished. So this is basically a simple concept of hook. But the interesting thing is that the customization here can go pretty deep. Cloud code allows you to define things to do before or after certain tools run or when you use it, try to send a new message to cloud code so that you can ingest additional context in. As well as when cloud tried to compress the composition history, or when a sub-agent finishes task. Now here's a more sophisticated example that I found actually pretty useful. So I can define this post to use hook. That every time after cloud code run a added multi-edid or rather. which means a modify or crease on new files. It will run this Python file I define here called type check. So this is a feature that I probably missed the most form cursor is that in cursor it has this automatic linked arrow detection. And this is really useful context so that cursor can capture those arrows even before you run the code and pre-atify fixed issue. But for Cloud it doesn't have this. And this will go basically replicate that functionality directly. So inside this Python file it might look a bit complicated but I will quickly explain to you what that means. So we're first they try to get input data. Each tool comes with a list of different inputs that you can use. For example for the post tool use input it will automatically give you a list data that you can use in this language tool it is. What does input agent generate for this tool and what's output of tool. In our case we want to get the file so we know which file it you just created or modified. Then we'll get the file pass. And if this file extension is TS or TSX which means it's type script we're around the type check. And if it's type check failed this is a part where we can send feedback bad to Cloud code. So you are doing the print and file will be system CD arrow. Here I defined as a code to be 2. So as a code 2 means that it is a blocking arrow and as the arrow will be fed bad to Cloud code. So that it can use that to define the next actions. But you can also define other as a code there where still send message bad to Cloud code but it won't blocking it from continue the next action. So with this hook if Cloud code generates on file that has type arrows it will automatically call the script and return back a arrow message if it has any type. So Cloud code can try to practically fix it. So this is how hook works and there are lot potentials. But you can even define some Quitic agent after Cloud code write any code it can write a test and validate it. Or if it write an API doc you can automatically update documentations. I have included a few common hooks that I use a lot in AI build a club. So you can go and grab. If you guys want a more deep dive or hook feature please come and below let me know I'm happy to do another one. On the outside Cloud code also have this commands feature where they do come with a list of predefined commands like check cost set up MCP memory models and review PR commands even but they also allow you to define custom slash commands. Well I can create a commands folder under Cloud and just create something called joke empty and make a joke in all caps. Once I did this I can do slash and search for joke then this command I defined here will be showing up. If I click on that whatever you define here in this command will basically be sent to Cloud code almost as a prompt. Then we'll start behave based on the rules you define there. I have another video where I talk about different commands that I pretty find that can help you extract specific starting from a screen shots as well as getting Cloud code into design mode to design multiple different UI iterations and you can even have a command to get a Cloud code to set up multiple different git work tree to have sub agents working parallel. So you can go check out this video if you want to learn more. And there's one package I saw this pretty useful recently called Super Cloud. It's an open source package that comes with a bunch of commands that they predefined and boot. For example I can do slash command SC analyze. This is a trigger that come in that take cloud into a much deeper code analyze mode. It will greatly lead us to do to look through the whole codebase and come back with a kind of architecture review. There are other useful things like you can run workflow to look at a PRD doc to get Cloud into kind of step by step implementation process as well as build command that will help bundle and implement build your projects as well as troubleshoot if you have some weird bug that you don't know how to fix. So this is really useful package. Even though installation is not as straightforward we need to open a folder to UV in it first to set up a pysam project and then do UV as super cloud. This will add this super cloud package and in the end do UV run pysam super cloud install. Then it will take us to the step by step installation process but once you install it will be installed at global level so you don't need to keep doing this. And all the file will be based on save to your doc cloud settings at the user level. If we open it it will basically add stuff into the cloud or MD which linked to all the different files that come to more details. Inside this command folder you can see all the commands that they define here. So this is a quick example of how far the customization you can do is just command feature. Meanwhile the list of very useful feature and shortcut that cloud code has there are no initially. Firstly I can do slash research to jumping back to a past conversation history and continuous conversation there. This is kind of similar to cursor where you can choose a past conversation but on the other hand they also introduce this export command. So this feature will allow you to copy the whole conversation history with cloud code. So you can jump between cloud code, cursor, we serve or any other coding IDE because you just need to pay the in conversation history and don't need to worry that cursor don't have the context about what it has been done. And quite often I will also go to cloud where I have unlimited amount token to do some early exploration. Apart from that another reason. useful feature is that you can double tap exit and this will allow you to river back conversation history to a past point so you can just click there and continue the conversation from that point. This really good because sometimes Cloud Core will make mistakes and this can avoid it. The only downside is that if you incur a server whenever a bad way past conversation it will automatically river back all your files as well. But Cloud Core didn't keep a snapshot. So you actually need to use some external package to do the snapshot and versioning. One of them is called CC bound do. So this is the package that will automatically delete the tag all the change that Cloud Core has made to a file and allow it to roll back. So I can do CC bound do and list this will list all the change that your Cloud Core has been made and you can do CC under preview to see the specific change that Cloud Core has been made and then once you confirm you can do CC bound do and so let the change you want to revert. So this package can work with Cloud Core handing and pretty well. So the command line might not be the best and easiest way for you to preview the work. There are more user friendly version like yo yo where it will save a snapshot and you can add some additional instructions to remember what the change is. And that's quite a useful shortcut is that you can type in the acceleration mark. This will get the Cloud Core into bash mode. So bash mode allowed to run command diarthae without going outside Cloud Core. So I can do quick shortcut like PMPM install, or PMPM as a package and it will just run a command diarthae here. So it is really fast but also the more important part is that this context would be part of conversation history so that Cloud Core will know what other actions they've been taken. And similarly you can also do hash tag or to activate the memory mode. So here is where you can type in things that you want Cloud Core to memorize. Like I'm Jason we're building on ID Union chassis and component and then it will ask you to choose where do you want to save this memory. I can be part of your level or can be used a level that across all the projects. And once you confirm it just save that information to the Cloud.m. And last part I also want to show you the easiest way for you to connect Cloud Code to KimeK2 model. If you don't know KimeK2 model is a new open source coding model that has similar performance like Cloud 3.5 to Cloud 4 but 80% cheaper. So it is really good to want to experiment if you run out of credits. And the easiest way to set up is that you can open terminal and do code open this thought. They s h r c file. If you are on Mac like me you probably just do this. But if you are on Windows you might need to change to bash. This will open a file like this. So this will basically control your terminal behavior. So here I already found KimeK2 API key and don't worry I already disabled this key so it's not going to work for you guys anymore. And I can define Kime where it will explore and drop a base URL to moonshot using this API key and run Cloud. So with this one I can just go to my any terminal and then do KimeK2. This will open Cloud Code with the special model that I defined there. So if I type in high here it is actually going to talk to the KimeK2 model. And similarly you can also define things here like Cloud, bash, maintain, project, working directory to be one. What this will do is that every time when Cloud is running it will always append the current working directory into the prompt. So it will always remember where it is. Instead of running commanding run place. So here is a quick overview of how I use Cloud Code. If you want to learn more you can join AI Build a Cloud where we have weekly sessions to talk to the latest workflow and tips for AI coding and build large learning models. As well as all detailed rules, hooks and commands that I personally use. So you can copy paste that right there. And in upcoming weeks we will have more detailed breakdown of how does the Cloud Code actually work behind the things and try to rebuild the Cloud Code from scratch so that we can learn the best practice of building effective AI coding agents. I put a link in the description below for you to join. I hope you enjoyed this video. Thank you and I see you next time."


URL,Transcription

Video URL: https://www.youtube.com/watch?v=amEUIuBKwvg

Video Transcription:
"I have been addicted to Cloud Code the past couple of months. I live and breathe in this terminal. There's a reason why I've been covering it and context engineering so much on my channel recently. The things we can do with these tools and frameworks now is insane. I feel like I can build anything. But as much as I've been talking about it on my channel recently, I haven't actually covered a start to finish. Let's dive into all the features of Cloud Code and how we can make the most out of this beautiful coding assistant. So that is what I'm going to cover with you right now. We're going to talk about best practices, strategies and tips for global rules and commands and agentic workflows and hooks and sub-agents and parallel agents. I'm going to dive into it all with you. So even if you've used Cloud Code a lot before, you're still going to get a lot out of this. Also, I know that Cloud Code is not perfect. Anthropics, new rate limits, outages, the cost. And so as we go through these strategies, I'll also talk about how they apply to other AI coding assistants as well. We're definitely not limited to Cloud Code, but it is the best of the best by far. And so yeah, just a value packed guide for you today. Let's go ahead and dive right into what I've got for you. So all of the tips and strategies that I've got for you today, I'm going to have in this readme, which I'm going to be adding into the context engineering GitHub repo that I've been building up recently. So I'll have a link to this in the descriptions. You can follow along with me, implement all of these strategies as we go through them together. And so context engineering and the PRP framework, my big things recently. I'm going to cover that in this guide, but also some other things I've never covered on my channel before, that are really important for making the most out of Cloud Code. And so just to give you an overview of all the strategies we're going through today, I want to start with global rules with the Cloud.md files and best practices for using those. Then dive into permission management. We'll go into custom slash commands so we can set up these agentic workflows that we can run with a single command. Then we'll get into MCP servers. And I've got a couple of big recommendations for this. Also a huge teaser for the overhaul for Rcon, Rcon version 2, which is going to be released next week. We got a beta launch for that. More on that in the middle of this video. So stay tuned for that. Then we'll get into context engineering with the PRP framework. I'll just give you a quick overview of this. And how you can get started in a three step process. Have this full framework for context engineering that gives your AI coding assistance everything they need to build production ready software for you. Then we'll get into leveraging subagents. One of the newer features of the Cloud Code that's super super exciting. And then we'll also get into Cloud Code hooks. So you can have these automations built in a different parts of the development life cycle as we are using Cloud Code. Then after that, we will go into the GitHub CLI integration. It's really amazing just how much Cloud Code can integrate directly with GitHub. Doing things like managing issues and PRs in our repo. And automatically creating PRs based on requests that we have for us. We'll dive into that here even with a slash command to automatically fix GitHub issue. So go out to GitHub find an issue, make a fix for it, create a pull request. We'll see that in action. I'll also dive into what is called the yellow mode. So we can run Cloud with dangerous permissions but do it in a safe way in containers. And then last but not least, I want to dive into parallel agent developments. We can have multiple instances of Cloud Code operating on different parts of our code base. Or all attempting to implement the same feature at the exact time. So we have different options to choose from. And that'll wrap it up for everything that I want to cover with you today. So I hope you can see from this. No matter how experienced you are with Cloud Code at this point, there are going to be some nuggets in here for you. And maybe even completely revolutionizing the way that you use Cloud Code. All right. So I have a completely empty folder open up in my IDE, except for the read me that has all of our strategies. I just copied over from the template that I have linked in the description. And even if you have never used or installed Cloud Code before, I've got you covered because I have their super simple installation steps at the top of the read me here, which for mac and Linux. It's just a single command. They also added support for Windows recently, but I still have a better experience with the Linux subsystem within Windows. So I've got instructions for that here, just a couple of extra steps, which I actually followed to install it myself. So within my IDE, I do control J to open up my terminal. I have a Ubuntu WSL1 running. And then I run the Cloud command. And there we go. We have our terminal open. And it's so easy to get started with Cloud Code. You just have to tell it what you want it to do. Like I have a question about my repository, or I want you to implement XYZ. Just go ahead and get started. If you're new to Cloud Code, it just throw in some commands. See what it's capable of doing. And then when you want to take Cloud Code from being good to great, that's when you want to start implementing all the strategies that I'm going to get down a dirty and cover for you right now. And so we'll start with the first one, which is our global rules. Basically, the system prompted to steer Cloud Code, so that we can have it behave the way we want it. Your claw.md file is like your Winster of Rules or your cursor rules if you use other IDEs before. It's the high-level instructions where you want to put things like your best practices or patterns that you want it to follow. It's basically the system prompt that you get to craft four clawed code. And there are two ways that we can create it. The first one, the easiest way, is to use the built-in slash init command. So going into my terminal here with Cloud Code, if I type in slash init, this is going to walk me through an initialization process where the creation of the clawed.md is a part of it. So Cloud Code will walk me through creating the system prompt for itself. But what I like doing even more is creating my own clawed.md. So that like being really meticulous about this instruction set, since it is really like the highest level instructions that we have for our coding assistant. And so as an example that I have for you, if we go back to the repo that I have linked in the description, I have a clawed.md prepared for you. Which is generally what I use when I build Python based applications. And so you can use this as a template for Python. And then also within the dynamist community, we're working on a different clawed.md templates for different kinds of projects like building agents or building next to apps or rust applications, we're creating all of these templates. And we're doing it as a part of a community initiative. The context engineering hub is something that we started recently in dynamists that I'm super pumped about. Basically, we're creating this gold mine of AI coding resources. Like, global rules like we're just talking about, clawed hooks, sub agents and different slash commands and PRP templates. Like no matter what you want to build, you can come here, find resources to save you hour, setting up that initial context for your AI coding assistant. So definitely check out dynamist.ai. If you're interested in this and want to be a part of this. And so I took the Python rules from that resource. And I have that available for you just to get started with something here. And so what I can do in the root of my folder here, I can create a new file and just call it claw.md. And then I'm just going to go ahead and copy and paste the contents from the template that I have available for you. So this is how easy it is to set up global rules for your coding assistant with clawed.md. And so now what you can do is you can go in your terminal here and you can just ask it what system instructions do you have? And part of what it'll cover here is the claw.md. We didn't even have to read it explicitly because it's just brought in automatically. So here we go. We got things like kiss and yagni, which we have covered directly in our claw.md. And also you can have a multiple claw.md's at different levels of your repo. And so I'll show you what this looks like right now. Just as the example that I have here, you can have a claw.md in your front end folder. Then one of your back end folder. These aren't read by clawed code automatically, but there is system prompting under the hood and clawed code. So it understands like if I'm operating in the front end folder and I see a claw.md there, I should look there for front end specific context. So it's very intelligent about how it works with these. And then another really pro tip that I have to give you here is that a lot of teams are starting to use claw.md's in a very sparing way. As in they don't put a lot of context into the claw.md. Instead they have their patterns and best practices and other business documents outside of their claw.md. And then they just reference those files in their global rules here. So that way it's a lot easier to share things between your team members. It's easy to switch between AI coding assistance, which is something else that I told you that I would be talking about here. And so yeah, that's a really powerful way to manage your global rules. And then also I have a note right here. Other AI coding assistance, they always have some kind of global rules or steering documents, whether it's cursor or a kiro or a augmented code. They all have this notion of global rules. Also one last thing that relates to global rules is prompting strategies for clawed code. And man could I make a full video on this. But a couple of things I want to call out really quickly. There are keywords with clawed code. Things like important, proactively ultra think. They're actually built into the model. So it's important to use these when appropriate. Definitely try some of these out. Like the tri-throwing ultra think into a prompt and just see how much more it'll use tokens to think through a problem. Also, clawed loves to over-engineer an implement old code or keep old code for backwards compatibility. So prompting against things like that. Keywords like production ready that cause it to over-engineer. Definitely important to keep in mind. So yeah, there's that like a gold mind of information that I have for prompting. I just wanted to throw out a couple of things here to really help you as you're making your global rules and even prompting beyond that. Next up we have permission management. So by default, clawed is going to ask you for permission before it does any command or edits any code in your code base. And that's good for security purposes. But we also don't want to always have to improve it for every single little action that it takes. And so we can set up a set of commands that it can run without asking for our permission. And so there are two ways that we can do that. The first way is that we can use the permissions command in clawed code. So when I go through this, it'll walk me through and allow list and it annihilists. And I can set up all these... rules right within the CLI. The thing that I like doing though is I like defining these myself in the settings.local.json files. This is a special file that lives in our dot cloud directory. And this dot cloud directory is what we'll see other things like slash commands and sub-agents going forward. But within this file, I can allow all of these actions within this JSON. And so within the template that I have for you, I have a settings.local.json with all the commands that I usually like to give a permission to run without my approval. So things like GrapinLS so it can search through our code base, moving directories and making directories, running Python commands. I like it to do all these things for me. Now something that I never add to this list is I never add the RM, the remove command. Because I always want to approve before it deletes any files. And so it's one of my recommendations that I have here. And the other thing is never just to give it bash star. Because this means that I can run any command without asking for your approval. So you want to be explicit calling out different commands or groups of commands that you want to run. Versus just letting it run everything. That is way too dangerous. And if you really do want to do that, then you can run in Yolo mode in a dev container, which I'll cover later on in this guide here. So that's everything for permissions. It's really nice to have this setup right out the gate. So that it can operate more autonomously and you don't have to babysit it as much. And so with that, we can move on to mastering custom slash commands. This is where we can build our own agentic workflows just as simple prompts for cloud code. And all you have to do to create a slash command is within your dot cloud folder. You have to create another folder called commands. And then you can create a slash command as a markdown file. So I'll call this primer dot md. This is one of the examples that I'll pull from our template in a second here. And so this is where we create a set of instructions that we can reuse basically as an advanced prompt for cloud code. You can get very elaborate with these. Like I said, building entire agentic workflows, guiding cloud code through a multi-step process. So I'm going to keep it simple right now. I just know that you can take these really, really far. And so the example I'm going to use here is priming context for cloud code. So it's a set of instructions, a set of steps that I'm telling cloud code to take in order to get it up to speed with a current code based on I'm operating on. So it's a really powerful command to run for cloud code when you're working with an existing code base, but you're starting in brand new conversations. You're coming in fresh with cloud code. You want it to catch itself up on the code base before implementing a new feature. And so it basically is just a prompt that we have here, which by the way, for other AI coding assistance like cursor and curo that don't have the slash commands, you can literally just use this as a prompt. And so the nice part about having this as a slash command though is that it's just very reusable. Like instead of us having to copy and paste this or type this out in a cloud code, we can just do the slash command. I'll show you what that looks like in the second. And it's also just very easy to share prompts with your teammates when you can just send them these commands that they can run with a single line. So this primer right here, now what we need to do to run it is I'm going to go back into cloud code. I'm going to exit out of cloud code and start a brand new session. So we load in all the new commands that we've added in our dot cloud folder. And then we can slash primer. And so I'll go ahead and run this. And it's going to start following all of the commands that we have listed out here. So we'll start by using the tree command. We'll see it do that. And then it'll read the cloud on MD and the read me. So it's going to do those one at a time. There we go. So at ran the tree, we'll see it read the cloud on MD next. There we go. All right, so you get the idea with this. So we're priming our context here. And so going back to the read me, the last thing that I want to cover for these slash commands is you can also have parameters with these slash commands with arguments. So when you have a slash command like this where you have this dollar sign arguments keyword, that means that whenever you invoke this command like slash analyzed performance and you pass in another parameter after a space here, that is going to fill in what you have for the dollar sign arguments here. So you're going to replace this keyword with whatever you type out here. So you can parameter try these slash commands. It's just another really nice thing to just make these commands working mean for you. And so with other a coding assistance, you can just like tell it to look at this command, use it as it's prompt. And then like for the parameter, I want you to use this value. So you can still do this while they're coding assistance, but slash commands just make it so easy with cloud code. Next up, I want to talk about MCP servers as awesome as cloud code is. There are still a lot of opportunities to enhance it with external tools and MCP is our way to connect cloud code to those. And so I've covered MCP a lot on my channel before, even how to use it with cloud code. But I've got some simple instructions here for how you can manage MCP servers and add them. I've talked about others on my channel before like my crawl for AIR egg or like super base or neon, so you can manage your database within cloud code. One that I really want to focus on here though. That's made a huge difference for me is the Serena MCP server. This one's incredible. I just found out about this last week and it is already doing a lot of good work for me. So this MCP server, it does a lot of the things that Claude Code does to understand your codebase and search through it and find the files to edit for changes that you ask for, except it does it better. It is an MCP server. It's all about semantic retrieval and editing your code. It's a very coding heavy MCP server. It's a game changer. And so we can add this into Claude Code to enhance its understanding of our codebase. So it's a wonderful MCP to work with existing code bases, which I know is something that a lot of you have been asking me to cover more on my channel. And so make sure you have UBX installed. This time you can install in WSL. And then we can add Serena just with this command. So I'll go into my terminal here. I'm not in the Claude CLI. I'm exiting it out of it right now. And so I can add the MCP server. There we go. We have added Serena. And then I can do Claude MCP list. And this is going to tell me the MCP servers I have connected. And it's going to verify the connection. Like we have with Arkon. I'll talk about that in a sec. And then also Serena. And we can also do Claude MCP or Moose Serena. If we want to remove that connection, obviously we don't want to do that right now. And so the other thing that we can do in order for Claude Code to be able to run Serena without asking us for permission is we can add it to our settings here. So I can say MCP underscore underscore Serena. That is the specific syntax to allow automatically access to all of the tools here. And so it's MCP underscore underscore and then the name of your MCP server. Like I can also do MCP Arkon. There we go. So now I was able to use all the tools from these MCP servers without asking for my permission, which I generally prefer. And I'd recommend doing the same. And then the other thing that we can do. I'm going to give you a live example of Serena here. I edited my primer dot MD this slash command to specify. I want you to use Serena to search through the code base and then just keep trying to use Serena if you get any errors because that happened sometimes. But yeah, we're going to change the behavior of our slash command leveraging this new MCP server. And just to give you more complete example, what I'm going to do here is add some stuff into the code base. So I'm just going to take this here and copy this. I'm going to take what I have for the patented AI PRP template. I cover recently on my channel. I'm just going to add this as content to our repo here. So we have something for it to search through with Serena. So okay, we got a more complete code base here. Now I can go back into cloud and I can run that primer command again. But this time it's going to behave a lot differently. There we go. I'll send off the primer and it's going to start by using the tree command just like before. It'll read the cloud dot MD and the read me. But then in a second here, and I'll skip down to this for you. Okay, actually every code. It's already starting to use Serena. And so we'll see it leverage different tools in the Serena MCP to really understand my code base. Take a look at this all these different calls to Serena and I had to prove not to them because I already added them into my settings dot local dot json for the Serena MCP. And so I'm not going to go through like show the full output of this command here, but yeah, it's just going to have a much better understanding of our code base, especially as our code base gets larger. That's when cloud code can start to fall on its face and you want to have tools like Serena. And then the last thing for MCP is me and a few other guys in the dynamist community are working on a massive overhaul for our con. We're going to be making it the MCP server for AI coding assistance and I cannot wait for this. It is going to be the knowledge and task management backbone for all AI coding assistance. And this Wednesday the 13th my next video at 7 p.m. central time. It's going to be our official open source beta launch of this new version of our con. And as another celebration we have a launch part. I'm going to be doing a live stream on Saturday the 16th at 90 of central times. So definitely mark your calendars for that. This is going to be a huge celebration for our con, which has an incredible user interface now. You can manage tasks for your coding projects with your coding assistance in real time. So as it updates things through the MCP server and as you're updating things, you're communicating back and forth in real time. We've got knowledge as well so you can crawl documentation kind of like my crawl for AI, Rage MCP and we have all those different strategies that I've been working on. We've been pouring our heart and soul into our con. So this is just giving you a little bit of a teaser right now. So much more coming for this very very soon. The next strategy that I want to dive into with you is context engineering with the PRP framework. And I've covered this a lot on my channel recently. So I'll link to a video right here if you want to really dive into this because it really does deserve its own video. Like a lot of the things that I'm covering here. So by the way, if you want to see more of one of these strategies in a complete video, definitely let me know in the comments. But context engineering with the PRP framework. The rest at process for us to define exactly the feature or new project we want to create. We generate a comprehensive document for context for our coding assistant. and then we execute it. And we have instructions as slash commands to take care of the last two steps for us. And so I'll just walk through this process really quick. Definitely check out that other video if you really want to dive into this more. And so within the PRP's folder, this is always where we define our initial.md. This is where we outline what we want to build. Any kind of examples I want to give it or documentation, any other kinds of considerations that we have for it. And so I'm taking the template that I have for you that I made earlier on my channel with building PIDantic AI agents specifically. So I'm just using this as a simple example here. So you describe your feature, which in my case, to keep it really simple, I'm just going to use the default that I have here. So I'm going to build a simple research agent using PIDantic AI. And then a lot of times it's helpful to describe the tools, dependencies, and system prompts that you want for your agent. I'm just going to delete this to make it really simple and fast for our purposes here. You want to provide any examples that you have for the PIDantic AI use case that I gave for you guys. I have examples already in here for different agents built with PIDantic AI. So I'm referencing all of these here so that when we generate our PRP, that's that long or form prompt that has all the context for the coding assistant. It's going to have all these examples within it. So it'll reference those things, bringing in to context, so it has those examples to build off of. And then same kind of thing with documentation. So referencing things from the PIDantic AI documentation directly. So it reads those pages. So we're telling it explicitly where to go look to get all the information that it needs. And then just any other kinds of considerations that we have here. Some things that I see it messing up on a lot like how it manages environment variables, so I'm just calling it out right here. So you create your initial.md. And then going back to the read me. The next step after that is we need to generate our PRP. So I'll go back into Cloud Code here. And I'm going to clear the conversation because we're going to just start from fresh here. And I'll just say slash generate PIDantic AI, PRP. Or whatever your slash command is called to generate your product requirement prompt. And then we just give it the path to our initial.md. And so I'll kick this off. It's going to take a little bit. So I'll pause and come back once it is done. But all this is going to do is go through my initial.md. Do any of the research that I have to do to grab all that context form that super long prompt. That we're going to execute in our last step. And take a look at this. It's even using our con under the hood. I didn't even tell it to. We have the MCP server connected. So it's using that for rag, searching, and looking at our code examples here. So you're getting a little bit of a taste of how our con works. You'll see this a lot more in the beta release next week. But yeah, basically what we're doing here and when we're generating APRP is we're basing everything off of this base PRP. This is the template that we're using to create this large prompt that we're going to execute in the next step to generate all of our code. So we cover core principles for Penanticai, what to do and not to do. So I've crafted this base PRP very specific to building AI agents with Penanticai. Covering all the context we need. Something else I really like about PRP is we cover the different tasks. Like here's what you should do step by step to build an agent with Penanticai. Then we get into validation loops, aka validation gates. So telling the AI coding assistant, how we can validate itself to make sure that its output is good. According to what we care about for AI agents. It's really, really nice to find all checklist, some anti-patrons. That's basically what we're going to have it create here. But specific to the agent that we want to create from our initial.md. And there we go. Our PRP is generated and you always, always want to validate your PRP's before you execute them. Make sure that it complied with the base PRP that everything's filled into your specifications, that everything looks good. Like if you gave this to another engineer, they can go ahead and use this to implement the agent end to end exactly as you want. That's the goal that we have with such an extensive prompt as a PRP. And so yeah, this looks perfect to me. So now I can go ahead and execute this. And so I'll go back into Cloud Code. You generally want to clear the conversation with slash clear. We want to start with fresh context here, because the PRP has everything that it needs. And so now we can do the other command. Instead of generate, it is execute PRP. And so then we'll again, we'll just give it the path here to the brave research agent.md. There we go. So now we're kicking this off. It's going to build the full agent for us. So it'll read the PRP first, because that's the argument that we're giving the slash command. We talked about arguments with slash commands earlier. And then it's going to go through it. It's going to read anything else that we have in our structure here, including all the examples that we told it to. It's going to do web research on the documentation. It's even using Serena. Take a look at this. So it's using Serena to understand our code structure. It's going to be using R-Con for R-Con as well. There's so much happening under the hood. And so I'm going to pause and come back once we have our complete implementation. And there we go. After about 20 minutes, we have our AIA. And just like with the PRP, I would very much encourage you to go through and validate the code that was outputted here I did that off camera. I iterated twice just to clean up a couple of things and now I can go ahead and run this agent Just show you really quickly that we have things working here just the power of context engineering And it is a very very basic agent just to give you a demonstration here But it's a nice seal. I that we have we've got streaming it has a tool for web search I can say what is the net worth of Jeff Bezos in 2025 and it'll even show us that it's using the web search tool We've got the text streaming and the conversation history. It's a pretty nice agent We have built here in a single shot thanks to PRP thanks to the examples that we referenced in the documentation in our initial.md So just showing you at a high level What it looks like to do context engineering with the PRP framework and so with that I want to move on to the next step that I have for you here, which is making our coding process even more powerful With PRP really with anything and it's thanks to having a specialized Intelligence in our coding workflows thanks to cloud code subagents So with subagents our primary cloud code agent is given the ability to call upon any of them and the Pride Mary agent is one that actually prompts the subagents So I'm very important understand how that works. The subagent has its own context window So we're not bringing in the entire conversation history into each subagent We're only including a prompt for our subagent that is crafted by our primary one Based on how it knows how to use that subagent. We'll see what that looks like in a little bit and Subagents are very powerful because they each have a specialized system prompt We can limit the tools that they have access to and they work autonomously and delegate attacks our primary agent can also kick off many subagents in a parallel So it's another very easy way to add parallel agent execution into our coding workflows and all of our agents They live in the dot cloud folder and a new folder that will create here called agents and there are two ways We can create our agents just like with our global rules. There is a slash agents command It's kind of like slash in it where cloud code will actually walk us through creating our agents So I'll put a file kind of like this or we can just build these files ourselves There's a couple of templates that I have available for you here So feel free to grab these from the agents folder and they get how repo links below One of them that I want to show you right here just a quickly show you the power of subagents is One that a rasmus the creator of the PRP framework. He actually built this for validation gates So validation gates is a very important part of the PRP framework because at the end once we have executed the PRP and we have our code output It we want our agent to operate autonomously writing tests Interrating on those tests and tell its confident that the code is working and so we can build a specialized agent to handle that And so I'm gonna make a new file in the agents folder or call it validation gates dot md So these are marked out files just like our global rules just like the hooks will get into in a little bit And we have a unique system prompt here telling it exactly how to implement and validate our Validation gates and so at the top we have the name of our agent then we have a description the description is really important Because this is what tells our primary cloud code agent Here's what this subagents all about and also how you can invoke it So really telling when and how to use this subagent and then we can also describe the tools that it has access to There's other parameters as well like we can even specify the model like we want to use on it for or Opus for we can specify that for the subagent so this is our agent not going back to the read me here I just want to say that while other AI coding assistants don't have the formal idea of subagents built into their platform like cursor or a kero or Client or whatever you can achieve something very similar just with prompts and really just like our global rules just like our slash commands All of these subagents are really just prompts and so you could just have a folder that's filled with all of these different prompts And you could have your global rules say like okay when you get to this point in the development flow Use this prompt to perform validation gates or to update the documentation whatever that might be so you can achieve something very similar It's just so easy the way that we can implement agents with cloud code being able to have things like Descriptions and tools and specifying different models It's a lot more flexible than if we just have to do with only prompts. It's not a still a reason to do this But yeah, let me go ahead and show you a demo of this so within a new cloud code session You have to refresh your session to bring a new agents just like new slash commands I'm saying here's my validation gate. I want you to make sure all the tests for the brave a search agent are Working and I'm not being explicit for to use the sub agent I mean I'm being kind of explicit saying validation gate here This is just assimilate more with it look like when we're operating in the middle of a PRP because that is a key word that we use validation gate And there we go. It's now calling upon our specialized sub agent and our sub agent is making this task list. It's handling everything in a separate conversation window. Then it's going to pass control with an output back to our primary agent that will continue the flow or give the final response to us. So we don't have to see this whole process right now. I just want to demonstrate really quickly how the primary agent is going to intelligently figure out when the call upon subagents based on the description that we have here. Next up we have Claude Hooks, which is a very powerful way to add deterministic control to Claude Coads behavior. So we have all these keywords here. After any of these actions, we can invoke our own custom command. And so before we use a tool, after we use a tool, after we use a subagent, we can have our own custom command that runs. It's really powerful. And this is built into Kero as well. But it's not in other AI coding assistance. I definitely think though because Claude Coads the industry leader and you always copy the industry leader, we're going to see these other IDEs like Kerochero Winster of an Augwyn code implement Hooks as well. It's really, really powerful. And so yeah, all you have to do to add Hooks here is you have to define them in JSON and then add them to our settings.local.json. So I usually like organizing them in a Hooks folder. And then I just have a JSON file here. I can just call this whatever I want Hooks.json. And then I have a couple of Hooks in the template for you just to introduce yourself. These are really, really basic hooks, but just introduce yourself to the different kind of hooks you can add and also different points in the development life cycle that you can have these actions take place. So I'm going to copy this, bring it into here, and then just keep it really simple right now. I'm going to bring it down to a single hook, which all then copy this JSON and put it in my settings below everything that I have for permissions that we already covered. So there we go. I now have this command that runs. It's going to run this bash script every single time that we finish invoking one of these tools. We're using this matchered also kind of filtered down after our tool use. And so then the hooks folder, I'm just going to create this file as well because I'm calling out the path in the command there. So log tool usage.sh. And then I'll just go ahead and copy the contents from the template. So there we go. It's really simple. You can also get parameters from your hooks. So I could do things like long the specific tools that are used here. But yeah, keeping it really simple, it says Cloud made and edit with a timestamp every single time. So it's going to call that now. As long as we refresh our Cloud session, so I'm going to clear certain new session with Cloud and ask it to make a change. So a little silly here, but I'm asking it to make just some random change to my dot getting nor. I don't really care what it does here. I just want to see that when I make a change, it is going to call my hook. And then we'll see something get outputted to a new logs folder that will be created in our dot cloud because that is where we're pointing to in our script. So I'll let it make the change to my dot getting nor here. There we go. And then just in a second boom, all right, we got our logs folder. And we have our dot log file, Cloud made an edit just a second and go looking really good. So that's hooks at a basic level. There's a little hot that you can do with them. It can honestly would deserve its own video. So yeah, certainly let me know in the comments if you're curious. I'm having a video diving into hooks or something like sub agents as well. Next up, I want to dive into the GitHub CLI using that with Cloud code. As much as Cloud code is useful, we're operating in our local development environment. It's also extremely powerful when you can have it operating within your GitHub repository. So you can have it manage issues and pull requests. That's what I want to show you right now. And so you can install the GitHub CLI just by following this link. And then there's a couple of commands that you need to run here. So first of all, just authenticating with GitHub. And so walk you through the OAuth flow. And then outside of Cloud here, so I'm going to clear this, you can just do GH repo. Let's just to make sure that it's working for you. So this will list all of your GitHub repository. So at this point, you're signed into Cloud. And now that you have GH in your development environment, you have the GitHub CLI command, Cloud code can start using this to operate on your remote GitHub repository. It's so powerful. And so like for example, what I can do here in my GitHub repo. So everything that we've been building together in this video, I have in this private GitHub repo. I can go ahead and create an issue right now. And so I'll open up an issue here. I'll say greeting for the brave agent. And I can say this is just kind of for demonstration purposes here. But I can say my brave agent needs to have a greeting when I first start the CLI. So just something kind of silly here. But I'll create this issue. There we go. And then the issue is number one. You can see that here and then also in the URL. And this will be important in a little bit because we're going to call out this issue to Cloud code and have it fix it for us. And in order for it to do that, I'm going to create a custom slash command. So I have this one also available in the template for you. So I'm going to copy this. I'm going to go into my dot cloud in my commands, new file, fix GitHub issue dot md.sh. That's it. There we go. It's all pasted. And... Basically what we're doing is walking through it when I give you an issue. This is the argument that we're passing here. It's going to be the issue number. Like in our case, it's just issue number one. It's going to use the GitHub CLI, GH issue view to understand the issue. It's going to look through our code base implementive fix. It's going to write tests and validate things, which that might even call upon our validation gates sub-agent. We'll see. It's going to ensure everything is good to go. And then it will also create a pull request. So it's going to push things to get out, maybe like a new branch it creates or whatever. And then it'll also create a pull request. So it's end to end. It goes out to GitHub. It does things locally. And then goes back out to GitHub with APR. So cool. So I'm going to go back into Cloud. I'm going to clear this. And then I'm going to execute this command. So it's just simply slash fix GitHub issue. And then my issue number is one. So go ahead and send this in a second. It's going to pull this comment right here. And it's going to use that to guide its development. Yep. So we got the issue right here. Greetings for the brave agent. And the text is cut off. But I got the full text here. Now it's creating a to do list. To fix everything. And it'll create APR at the end. So I'll pause and come back once it is done with this flow. And there we go. Let me full screen this story here. The full summary. It found the issue. After reading it from GitHub, implemented the fix, tested everything. Made a new branch, pushed it a hand created a pull request. All from a single slash command. And that's the power of slash commands with this full agent to work full that we created. That's the power of the integration with the GitHub CLI. So going back to my issue here, we can see that we have a commit a new branch referencing this issue. And we have a new pull request. So if I refresh here, we'll see a one next pull request. There we go. I can go in here. We can take a look at the changes that were made. So yeah, it made some tests. And then it also updated CLI. I'm just to add a nice screening here. This is looking so good. So I can go ahead and review these changes. I can merge them into my main branch. I can even have a cloud to help me do all of that. It's just beautiful. The integrations that we have here. And of course, there is a lot more you can do with the GitHub CLI with cloud code. You can even have cloud code integrated directly with your GitHub repo. So you can reference it within your issues and PRs, just like a normal developer and have it fixed things and create PRs autonomously. Really cool. So we're just scratching this surface here. But I just wanted to introduce you to what is possible with these kind of integrations. Next up, let's go on to the Yola mode with dev containers. Because at this point, we've already covered permissions. We have everything set up in our settings.local.json. We understand what it looks like to have things in place where cloud will do certain actions autonomously without our approval. And then other things like removing files, we generally always want to approve it before it does so. And one of the biggest reasons that we want to have these kind of protections in place for commands like removing files is because cloud code can theoretically remove things outside of our current project. It could delete really critical files on our computer. Worst case scenario. And I haven't seen that happen. But these are the kind of protections that we want to have in place in general. We're running cloud code directly on our computer. And so the solution for this, if you want to have a safe environment, but also have cloud never have to ask you for permission to do things so it can go and operate entirely autonomously. That's really want to enable Yola mode with dev containers. And so basically with dev containers, we run cloud code and its own isolated environments. So our entire machine is protected. We can also have firewall set up in place for the dev container. So it only has access to the websites we want it to. And so then we can run it with dangerously skip permissions where it will now no longer ever ask us for approval for anything and we can still be safe. And dev containers is an official idea for a man thropics. So they have this page in their docs, which I'll link to in the description below. You can read through this if you want to understand what they're setting up for us here. And they give us the Docker file in a couple of other things so we can create this dev container. And we can run these directly in any VS code. So you can also do forks like cursor and wind surf. We can run it with cloud code just open up in any VS code. So yeah, I'll show you how to do this right now. And I have this dev container that's included from anthropic. I have this directly in the template for you. And so what I'm going to do right now is I'm going to go back to the two folders here. I'm going to copy this dev container. I'm going to bring it right into the code base that we've been working on in this video. So there is our dev container. And then going back to our read me here, the way that we run this is we in VS code. We just have to press F1. We have to select dev container. And I'll say reopen in container. And this is going to automatically build up our dev container, open up a new VS code environment. I'm just using wind surf right here to run cloud code in the terminal. So it's going to be building the dev container. And then after a little bit, we'll have a new environment spun up operating entirely inside the container. So I'll pause and come back once that is ready. So there we go. And then the way that you know that you're in the dev container is just in the bottom left, it'll say that you're in the container, the dev container. We can go back to reopen folder locally. If you want to exit out of the container, go back to your... normal development environment. And so now if I do Control J to open up a terminal here and I do Cloud. This is going to open up a brand new Cloud code session and because I am in an isolated environment, basically a new virtual machine, it's walking me through the process to set of Cloud code from scratch and this makes sense. So I'll just go through the authentication flow right here. There we go. So I just open the link to authenticate with Cloud code. Went through the last couple of steps here and now we are within the Cloud. And what I can do by the way, if I clear this and it open Cloud again, this is where I can run the dash dash, dangerously skip permissions. And so we'll see in the bottom right here. So let me enter. So yeah, it's going to be a warning here. You are in bypass permission modes. Why accept this? And we'll see this in the bottom right that we are bypassing permissions. So now whenever I do something like right more tests, whatever it is. Like it's not going to ask me for approval before I edit anything. Even if it removes files, it won't ask for approval there either. It's going to do everything entirely autonomously. But also, we have protections in place. Like there's some firewall stuff. Then it's rapid built into this container. We have an allow list of websites that we can visit. So you can add onto that list as well. Definitely poke around with this. If you're interested in setting up this safe, Yolo mode, a dev container environment. And it's all thanks to this Docker file. So all this is coming directly from the Anthropic documentation. We now have our safe, Yolo mode. Last but not least, I want to cover parallel Asian execution with you in the Cloud code. We're going to do this with the idea of Git work trees. And there are a couple of different ways to implement parallel agents. So we saw one way with sub agents already. But this one's really powerful because of Git work trees. Basically, it's our way to have different branches for our GitHub repository open at the same time. And we'll have an instance of Cloud code operating on each of them. So we're guaranteed isolation. And it'll be tripping over each other's toes because they all have their own branch open up. So we have the code base duplicated across these different work trees. And then basically, after we implement whatever changes we want in each work tree, we can find the one that we want to merge in or maybe want to merge in all of them. And we can just bring them back into our main branch after each Cloud code instance is done. And so there's a manual way to set this up. And then there's an automated way that's really cool with slash commands that I want to focus on with you here. But let's start with the manual way really quick. So I'm not going to run through all these commands as a demo right now. I just want to call these out really quick. Basically, once you have your different feature branches created, like feature slash off feature slash API, you can now add work trees. And so you just call out the branch that the work tree is going to be based off of. And then you give a path to your local file system where you want to basically replicate the code base into the work tree. So it actually duplicates everything. So you have a completely isolated environment in a separate branch. And then you can just change into that directory and launch Cloud. And so you can do this in any number of work trees that you create. It's really, really easy. But it is pretty tedious for you to create all these branches, set up all these work trees, and then open up Cloud and every single one of them. And so I have an automated process for you that takes care of all this. This is what I really want to demo for you right here. And so there are a couple of slash commands that I have in the template for you going along with all the other ones that we've covered, like the primer and the PRP stuff that I want to bring in right now. So the first one is prep parallel. So I'm going to copy this. I'll bring it into our commands and I'll explain it really quickly. So prep parallel dot md as in prepping the parallel execution of many different agents here. So we have a couple of arguments. We have the feature name. What is the name of this new feature that we want to implement? And then we're the number of parallel agents or parallel work trees that we want to have. And then just in a loop here, based on the number of parallel agents, it's going to create a new branch and a new get work tree. It's going to change into there. And it's going to just validate that everything is set up properly. And then we'll run the get work tree list at the end to make sure that we have everything set up. So we're prepping for the execution of many different cloud agents here. And for this example, what I have right here with parallel execution, this is specifically for having many different agents tackling the same feature in a code base. And so I also want to be clear here. Let me scroll it back down. I also want to be clear here that you can use parallel agents to work on different parts of your code base at the same time. Or like what we're doing here, we can use parallel agents to implement the same feature many different times. So we can pick the best implementation. It's just a faster way to develop. Because sometimes cloud messes up and you have to restart. But now we can just do all that at once. And so that is our prep parallel. The next one that we have, it's kind of like PRRP where we have a prep command and then we have the actual execute command. So execute parallel. I'll bring this in. I'll make a new file, execute to parallel.md. Let me fix the spelling there. Pre-name. Typles are not good. All right. So let me go paste in the full contents here. So we have the feature name as one argument. We have the. plan to execute. So this is just like our initial.md with PRP, where we will create. And I'll actually do this here. We'll have a plan.md. And this is where we'll specify everything that we want to implement for our new feature. And so I can just say something like change the brave agency ally to have red and orange colors for the primary theme. Just something very simple for a demo, just like we did with subagents. And so going back here to the command, we have our plan to execute. So we'll pass in the path to plan.md as this argument within the slash command. Then we have the number of parallel work trees. And this should just be the same number that we've passed into PRP parallel. And so now from the instructions here, we're just telling it like you're going to create a number of cloud code agents that are going to operate implementing the same feature. So we're just describing like read the plan and then here's how you set up the different work trees and executing the different cloud code agents. And then each of them make sure that they report their final changes in a comprehensive results.md so that we can go into each work tree after see what was implemented. We can test each one out. Find the one that we like the most. And then we can bring that one into our main branch. So that's the flow that we're going to go through right now. And so starting out, I'm going to go into my cloud here. I'm going to open up a brand new cloud session because I just created these slash commands. And so my command is going to be slash prep parallel. And then I need the feature name as the first argument so that is CLI UI updates. And then three, four, the number of parallel work trees. And so I'm going to send this off. It's going to go through the set of instructions and so I'll pause and come back once this is done. All right. So we created each of the work trees and verified everything. We can even see this here. If we go into this new trees folder, we have our code base replicated in each of these. This is exactly how work trees are supposed to operate. So we are now ready to execute our parallel process. So I'll go over to the execute parallel here. We got our three arguments. And so here's what I'll do. I'm going to actually clear the conversation here because we don't even need the context of prepping things. We can just dive right into the execution with no context. And so our command is going to be execute parallel. And then the same feature name. As well as call it the same name. CLI UI updates. Then we reference our planned on MD because that's where we're going to understand the feature we want to implement. And typically you'll have quite a bit more detail here. Just keeping this very basic for demo purposes. But this should be pretty fleshed out just like your initial.md's. And then going to execute parallel. And then we're just doing three, four, our number of parallel work trees. And by the way, if you want it to really take this far, you could combine this whole parallel execution with the PRP framework. Now that would be really cool. Something that I definitely want to play around within the near future here. But yeah, I'll go ahead and send this off. It's going to read the plan. It's going to dish that out to three different cloud code eight sub agents running at the same time implementing the same feature. And then I get to pick the best one at the end. And by the way, when I say that we have parallel execution here, I do mean that they are all running at the exact same time. You can see that here because we have the blinking light in three spots here. We have a task for each of our sub agents version one, two and three of the CLI colors implementation. Oh, and look, I think one of them. Oh, yeah, one of them already completed its first task here. So we're getting through the implementation. They're running at their own speeds all in isolation. And so yeah, I'll come back once we are done with all three. And there we go. We are done. And our primary agent even gives us a summary of what all the different sub agents did in the work trees here. So we have slight different implementations for the CLI UI updates. I'll actually show you what this looks like. So I took one of the sub agents here, the first one. And I just set up that environment with UV and my dot E and V just like I did with the original brain search agent. And here's what our UI looks like. And honestly, I'd like the original one more. I mean, this was just a silly example here, but it very much did implement to the red and orange exactly like I told it to. And each of the other ones are going to look pretty much the same. And then I'm not going to show it here, but going back to the read me really quickly. If I do want to pick one of these to bring back into my main branch, there's just a couple of commands that I need to run. So I can just do get checkout main. And I can merge any one of these branches that are work tree is based off of back into my main branch, pushing up to get hub. And that's how easy it is to have parallel agent execution and then bring it back into our main branch. So there you go. That is everything that I have for you today on using Cloud Code effectively. Going from start to finish all the different features that we have with Cloud Code and how you can get the most out of them. And I'm going to be totally honest, this guide did end up being quite a bit longer than I thought it would be. But I didn't want to skip out on the details here. I wanted to cover all these things meticulously. So you have just a super solid foundation and clear understanding of how we can get the most out of Cloud Code with all the beautiful features for things like slash commands and sub agents and hooks. And all these things really could deserve their own dedicated video. So I know that I mentioned this a couple of times throughout the video already. But definitely let me know in the comments if there's anything that I've covered here that you want me to expand upon a lot more. I do want to make quite a few more videos in the near future on Cloud Code and just AI coding in general because this is... future. And AI for coding is really one of the most exciting use cases of generative AI right now. So if you enjoy this video and you're looking forward to more things AI coding and AI agents, I would definitely appreciate it like and subscribe. And with that, I will see you in the next video."
